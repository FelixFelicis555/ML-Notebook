{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"data.csv\",delimiter=',')\n",
    "#len(data[0]),len(data[1])\n",
    "M = len(data[0])\n",
    "x = data[:,0:(M-1)]\n",
    "y  = data[:,M-1:]\n",
    "z = np.ones((len(data),1))\n",
    "new_d = np.hstack((x,z))\n",
    "new_d = np.hstack((new_d,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((127, 27), (127, 27), (127, 13))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = np.loadtxt(\"test_boston_x_test.csv\",delimiter=',')\n",
    "z = np.ones((len(points),1))\n",
    "new_d = np.hstack((points,z))\n",
    "cols = len(new_d[0])-1\n",
    "for x in range(0,cols):\n",
    "    z = new_d[0:,x]**2\n",
    "    new_d = np.insert(new_d,cols,values=z,axis=1)\n",
    "df1 = pd.DataFrame(new_d)\n",
    "df1.shape,new_d.shape,points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(points,m):\n",
    "    costt = 0 \n",
    "    M =len(points)\n",
    "    for i in range(M):\n",
    "        y = points[i,(len(points[0])-1)]\n",
    "        x_total=0\n",
    "        for j in range((len(points[0])-1)):\n",
    "            x_total += m[j]*points[i,j]\n",
    "        costt += (1/M)*((y-x_total)**2)   \n",
    "    return costt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addFeatures(X):\n",
    "    cols = len(data[0])-1\n",
    "    for x in range(0,cols):\n",
    "        z = X[0:,x]**2\n",
    "        X = np.insert(X,cols,values=z,axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Gradient Descent Code Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#iterate through all the data points and find the slope \n",
    "#for generic gradient descent you have only one array of m and the last c have a coeff of 1\n",
    "def step_grad(points,learning_rate,m):\n",
    "    m_slope =np.zeros(len(points[0]))\n",
    "    M = len(points)\n",
    "    for i in range(M):\n",
    "      #  x = points[i,0] this will not work we have to cal x_total (m1x1+m2x2+......)\n",
    "        x_total =0\n",
    "        for j in range((len(points[0])-1)):\n",
    "            x_total += m[j]*points[i,j]\n",
    "\n",
    "        y = points[i,(len(points[0])-1)]\n",
    "        l=0\n",
    "        for k in range((len(points[0])-1)):\n",
    "            m_slope[l] += (-2/M)*(y-x_total)*points[i,k]\n",
    "            l=l+1\n",
    "        #c_slope += (-2/M)*(y-m*x-c)\n",
    "    new_m=list([0 for j in range(len(points[0])-1)])\n",
    "    a=0\n",
    "    for i in range((len(points[0])-1)):\n",
    "        new_m[i]=m[i]-learning_rate*m_slope[i]\n",
    "    #new_m = m - learning_rate * m_slope\n",
    "   # new_c = c - learning_rate * c_slope\n",
    "    return new_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#as said in gd defnition we have to start m&c with any random value\n",
    "#substract the slope from the m or c till num_iter\n",
    "def gd(points,learning_rate,num_iter):\n",
    "    m=np.zeros(points.shape[1])\n",
    "    #c=0\n",
    "    for i in range(num_iter):\n",
    "        m = step_grad(points,learning_rate,m)\n",
    "        #use cost function not for calculating gd but for getting yourself idea of which way code is going!\n",
    "        #print(i,\"cost:\")\n",
    "        print(i,\"cost:\",cost(points,m))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we have to load data and send it to gd function to figure out m & c\n",
    "#gd requiires learning rate & number of iter\n",
    "#generic data requires addition of 1 as the coeff of c to each row\n",
    "def run():\n",
    "    data = np.loadtxt(\"training_ccpp_x_y_train.csv\",delimiter=',')\n",
    "    M = len(data[0])\n",
    "    x = data[:,0:(M-1)]\n",
    "    y = data[:,M-1:]\n",
    "   # x = preprocessing.scale(x_unscaled)\n",
    "    z = np.ones((len(data),1))\n",
    "    new_d = np.hstack((x,z))\n",
    "    new_d = np.hstack((new_d,y))\n",
    "    learning_rate = 0.1\n",
    "    num_iter =100\n",
    "    m = gd(new_d,learning_rate,num_iter)\n",
    "    #print(m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#no we need a predict fuction which pedicts the data by reading the values from test set\n",
    "def predict(points,m):\n",
    "    z = np.ones((len(points),1))\n",
    "    new_d = np.hstack((points,z))\n",
    "    y_pred = np.zeros(len(new_d))\n",
    "    for i in range(len(new_d)):\n",
    "        #y_pred[i]\n",
    "        for j in range(len(new_d[0])):\n",
    "            y_pred[i] += m[j]*new_d[i,j]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 8.85759744587e+15\n",
      "1 cost: 3.79857037336e+26\n",
      "2 cost: 1.6290124913e+37\n",
      "3 cost: 6.98600114249e+47\n",
      "4 cost: 2.99593847337e+58\n",
      "5 cost: 1.28480473352e+69\n",
      "6 cost: 5.50987017237e+79\n",
      "7 cost: 2.36290142186e+90\n",
      "8 cost: 1.01332752946e+101\n",
      "9 cost: 4.34564333689e+111\n",
      "10 cost: 1.8636240961e+122\n",
      "11 cost: 7.99213028388e+132\n",
      "12 cost: 3.4274157867e+143\n",
      "13 cost: 1.46984327803e+154\n",
      "14 cost: 6.30340582068e+164\n",
      "15 cost: 2.70320826268e+175\n",
      "16 cost: 1.15926772277e+186\n",
      "17 cost: 4.97150616029e+196\n",
      "18 cost: 2.13202464077e+207\n",
      "19 cost: 9.14316290131e+217\n",
      "20 cost: 3.92103478737e+228\n",
      "21 cost: 1.68153121297e+239\n",
      "22 cost: 7.21122707018e+249\n",
      "23 cost: 3.09252635079e+260\n",
      "24 cost: 1.32622633253e+271\n",
      "25 cost: 5.68750621847e+281\n",
      "26 cost: 2.43908043384e+292\n",
      "27 cost: 1.04599681024e+303\n",
      "28 cost: inf"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mrina\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: RuntimeWarning: overflow encountered in double_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "29 cost: inf\n",
      "30 cost: inf\n",
      "31 cost: inf\n",
      "32 cost: inf\n",
      "33 cost: inf\n",
      "34 cost: inf\n",
      "35 cost: inf\n",
      "36 cost: inf\n",
      "37 cost: inf\n",
      "38 cost: inf\n",
      "39 cost: inf\n",
      "40 cost: inf\n",
      "41 cost: inf\n",
      "42 cost: inf\n",
      "43 cost: inf\n",
      "44 cost: inf\n",
      "45 cost: inf\n",
      "46 cost: inf\n",
      "47 cost: inf\n",
      "48 cost: inf\n",
      "49 cost: inf\n",
      "50 cost: inf\n",
      "51 cost: inf\n",
      "52 cost: inf\n",
      "53 cost: inf\n",
      "54 cost: inf\n",
      "55 cost: inf\n",
      "56 cost: inf\n",
      "57"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mrina\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: overflow encountered in double_scalars\n",
      "  from ipykernel import kernelapp as app\n",
      "C:\\Users\\Mrina\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: overflow encountered in double_scalars\n",
      "  \n",
      "C:\\Users\\Mrina\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: overflow encountered in double_scalars\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " cost: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mrina\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:21: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 cost: nan\n",
      "59 cost: nan\n",
      "60 cost: nan\n",
      "61 cost: nan\n",
      "62 cost: nan\n",
      "63 cost: nan\n",
      "64 cost: nan\n",
      "65 cost: nan\n",
      "66 cost: nan\n",
      "67 cost: nan\n",
      "68 cost: nan\n",
      "69 cost: nan\n",
      "70 cost: nan\n",
      "71 cost: nan\n",
      "72 cost: nan\n",
      "73 cost: nan\n",
      "74 cost: nan\n",
      "75 cost: nan\n",
      "76 cost: nan\n",
      "77 cost: nan\n",
      "78 cost: nan\n",
      "79 cost: nan\n",
      "80 cost: nan\n",
      "81 cost: nan\n",
      "82 cost: nan\n",
      "83 cost: nan\n",
      "84 cost: nan\n",
      "85 cost: nan\n",
      "86 cost: nan\n",
      "87 cost: nan\n",
      "88 cost: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-75c69f2ca68c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdataTest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test_ccpp_x_test.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataTest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"comcycle.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"%.5f\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-0c57392597e4>\u001b[0m in \u001b[0;36mrun\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mlearning_rate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mnum_iter\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_d\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;31m#print(m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-35d160a0f071>\u001b[0m in \u001b[0;36mgd\u001b[1;34m(points, learning_rate, num_iter)\u001b[0m\n\u001b[0;32m      8\u001b[0m         \u001b[1;31m#use cost function not for calculating gd but for getting yourself idea of which way code is going!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[1;31m#print(i,\"cost:\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"cost:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-1eb900898027>\u001b[0m in \u001b[0;36mcost\u001b[1;34m(points, m)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[0mx_total\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mx_total\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpoints\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m         \u001b[0mcostt\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx_total\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcostt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "m = run()\n",
    "dataTest = np.loadtxt(\"test_ccpp_x_test.csv\",delimiter=',')\n",
    "y_pred = predict(dataTest,m)\n",
    "np.savetxt(\"comcycle.csv\",y_pred,fmt=\"%.5f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
