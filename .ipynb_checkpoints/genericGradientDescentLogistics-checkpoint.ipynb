{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.loadtxt(\"data.csv\",delimiter=',')\n",
    "#len(data[0]),len(data[1])\n",
    "M = len(data[0])\n",
    "x = data[:,0:(M-1)]\n",
    "y  = data[:,M-1:]\n",
    "z = np.ones((len(data),1))\n",
    "new_d = np.hstack((x,z))\n",
    "new_d = np.hstack((new_d,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((127, 27), (127, 27), (127, 13))"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "points = np.loadtxt(\"test_boston_x_test.csv\",delimiter=',')\n",
    "z = np.ones((len(points),1))\n",
    "new_d = np.hstack((points,z))\n",
    "cols = len(new_d[0])-1\n",
    "for x in range(0,cols):\n",
    "    z = new_d[0:,x]**2\n",
    "    new_d = np.insert(new_d,cols,values=z,axis=1)\n",
    "df1 = pd.DataFrame(new_d)\n",
    "df1.shape,new_d.shape,points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(points,m):\n",
    "    costt = 0 \n",
    "    M =len(points)\n",
    "    for i in range(M):\n",
    "        y = points[i,(len(points[0])-1)]\n",
    "        x_total=0\n",
    "        for j in range((len(points[0])-1)):\n",
    "            x_total += m[j]*points[i,j]\n",
    "        costt += (1/M)*((y-x_total)**2)   \n",
    "    return costt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#finding h(x) i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addFeatures(X):\n",
    "    cols = len(data[0])-1\n",
    "    for x in range(0,cols):\n",
    "        z = X[0:,x]**2\n",
    "        X = np.insert(X,cols,values=z,axis=1)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generic Gradient Descent Code Start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#iterate through all the data points and find the slope \n",
    "#for generic gradient descent you have only one array of m and the last c have a coeff of 1\n",
    "def step_grad(points,learning_rate,m):\n",
    "    m_slope =np.zeros(len(points[0]))\n",
    "    M = len(points)\n",
    "    for i in range(M):\n",
    "      #  x = points[i,0] this will not work we have to cal x_total (m1x1+m2x2+......)\n",
    "        x_total =0\n",
    "        for j in range((len(points[0])-1)):\n",
    "            x_total += m[j]*points[i,j]\n",
    "\n",
    "        y = points[i,(len(points[0])-1)]\n",
    "        l=0\n",
    "        for k in range((len(points[0])-1)):\n",
    "            m_slope[l] += (-2/M)*(y-x_total)*points[i,k]\n",
    "            l=l+1\n",
    "        #c_slope += (-2/M)*(y-m*x-c)\n",
    "    new_m=list([0 for j in range(len(points[0])-1)])\n",
    "    a=0\n",
    "    for i in range((len(points[0])-1)):\n",
    "        new_m[i]=m[i]-learning_rate*m_slope[i]\n",
    "    #new_m = m - learning_rate * m_slope\n",
    "   # new_c = c - learning_rate * c_slope\n",
    "    return new_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#as said in gd defnition we have to start m&c with any random value\n",
    "#substract the slope from the m or c till num_iter\n",
    "def gd(points,learning_rate,num_iter):\n",
    "    m=np.zeros(points.shape[1])\n",
    "    #c=0\n",
    "    for i in range(num_iter):\n",
    "        m = step_grad(points,learning_rate,m)\n",
    "        #use cost function not for calculating gd but for getting yourself idea of which way code is going!\n",
    "        #print(i,\"cost:\")\n",
    "        print(i,\"cost:\",cost(points,m))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#we have to load data and send it to gd function to figure out m & c\n",
    "#gd requiires learning rate & number of iter\n",
    "#generic data requires addition of 1 as the coeff of c to each row\n",
    "def run():\n",
    "    data = np.loadtxt(\"training_boston_x_y_train.csv\",delimiter=',')\n",
    "    M = len(data[0])\n",
    "    x = data[:,0:(M-1)]\n",
    "    y = data[:,M-1:]\n",
    "   # x = preprocessing.scale(x_unscaled)\n",
    "    z = np.ones((len(data),1))\n",
    "    new_d = np.hstack((x,z))\n",
    "    new_d = np.hstack((new_d,y))\n",
    "    learning_rate = 0.1\n",
    "    num_iter =100\n",
    "    m = gd(new_d,learning_rate,num_iter)\n",
    "    #print(m)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#no we need a predict fuction which pedicts the data by reading the values from test set\n",
    "def predict(points,m):\n",
    "    z = np.ones((len(points),1))\n",
    "    new_d = np.hstack((points,z))\n",
    "    y_pred = np.zeros(len(new_d))\n",
    "    for i in range(len(new_d)):\n",
    "        #y_pred[i]\n",
    "        for j in range(len(new_d[0])):\n",
    "            y_pred[i] += m[j]*new_d[i,j]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 cost: 374.240355979\n",
      "1 cost: 245.379096561\n",
      "2 cost: 165.106141922\n",
      "3 cost: 114.495086212\n",
      "4 cost: 82.4343266428\n",
      "5 cost: 62.0417046883\n",
      "6 cost: 49.015474666\n",
      "7 cost: 40.6551932602\n",
      "8 cost: 35.2597283507\n",
      "9 cost: 31.7541214926\n",
      "10 cost: 29.457161634\n",
      "11 cost: 27.9360070221\n",
      "12 cost: 26.9149224129\n",
      "13 cost: 26.217802952\n",
      "14 cost: 25.731872823\n",
      "15 cost: 25.3846991177\n",
      "16 cost: 25.1296035256\n",
      "17 cost: 24.9363844105\n",
      "18 cost: 24.785404792\n",
      "19 cost: 24.6638182219\n",
      "20 cost: 24.5631551436\n",
      "21 cost: 24.4777765182\n",
      "22 cost: 24.4038812007\n",
      "23 cost: 24.3388674349\n",
      "24 cost: 24.2809211483\n",
      "25 cost: 24.2287497324\n",
      "26 cost: 24.1814093006\n",
      "27 cost: 24.1381921201\n",
      "28 cost: 24.0985528595\n",
      "29 cost: 24.0620599382\n",
      "30 cost: 24.028363159\n",
      "31 cost: 23.9971719425\n",
      "32 cost: 23.9682404978\n",
      "33 cost: 23.9413575577\n",
      "34 cost: 23.9163391409\n",
      "35 cost: 23.8930233395\n",
      "36 cost: 23.8712664786\n",
      "37 cost: 23.8509402168\n",
      "38 cost: 23.8319293041\n",
      "39 cost: 23.8141298077\n",
      "40 cost: 23.7974476758\n",
      "41 cost: 23.7817975557\n",
      "42 cost: 23.7671018013\n",
      "43 cost: 23.7532896315\n",
      "44 cost: 23.7402964057\n",
      "45 cost: 23.7280629961\n",
      "46 cost: 23.7165352383\n",
      "47 cost: 23.7056634488\n",
      "48 cost: 23.6954019975\n",
      "49 cost: 23.6857089292\n",
      "50 cost: 23.6765456252\n",
      "51 cost: 23.6678765022\n",
      "52 cost: 23.6596687413\n",
      "53 cost: 23.6518920452\n",
      "54 cost: 23.6445184199\n",
      "55 cost: 23.6375219771\n",
      "56 cost: 23.6308787565\n",
      "57 cost: 23.6245665645\n",
      "58 cost: 23.6185648281\n",
      "59 cost: 23.6128544628\n",
      "60 cost: 23.6074177516\n",
      "61 cost: 23.602238236\n",
      "62 cost: 23.597300616\n",
      "63 cost: 23.5925906589\n",
      "64 cost: 23.5880951163\n",
      "65 cost: 23.5838016484\n",
      "66 cost: 23.5796987539\n",
      "67 cost: 23.5757757068\n",
      "68 cost: 23.5720224981\n",
      "69 cost: 23.5684297817\n",
      "70 cost: 23.5649888259\n",
      "71 cost: 23.5616914676\n",
      "72 cost: 23.5585300713\n",
      "73 cost: 23.5554974902\n",
      "74 cost: 23.5525870318\n",
      "75 cost: 23.5497924246\n",
      "76 cost: 23.5471077887\n",
      "77 cost: 23.5445276081\n",
      "78 cost: 23.5420467047\n",
      "79 cost: 23.5396602155\n",
      "80 cost: 23.5373635704\n",
      "81 cost: 23.5351524718\n",
      "82 cost: 23.5330228766\n",
      "83 cost: 23.5309709784\n",
      "84 cost: 23.5289931918\n",
      "85 cost: 23.5270861375\n",
      "86 cost: 23.5252466286\n",
      "87 cost: 23.5234716579\n",
      "88 cost: 23.5217583859\n",
      "89 cost: 23.5201041303\n",
      "90 cost: 23.5185063554\n",
      "91 cost: 23.5169626627\n",
      "92 cost: 23.5154707824\n",
      "93 cost: 23.5140285648\n",
      "94 cost: 23.5126339733\n",
      "95 cost: 23.5112850767\n",
      "96 cost: 23.5099800431\n",
      "97 cost: 23.5087171337\n",
      "98 cost: 23.5074946969\n",
      "99 cost: 23.5063111632\n"
     ]
    }
   ],
   "source": [
    "m = run()\n",
    "dataTest = np.loadtxt(\"test_boston_x_test.csv\",delimiter=',')\n",
    "y_pred = predict(dataTest,m)\n",
    "np.savetxt(\"bostontry2.csv\",y_pred,fmt=\"%.5f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
